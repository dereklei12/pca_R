---
title: "PCA/Partial PCA for scRNA-seq Data"
author: "Ziqi Lei"
output:
  html_document:
    df_print: paged
---

```{r setup, message=FALSE, warning=FALSE}
set.seed(2025)
suppressPackageStartupMessages({
  library(ggplot2)
  library(dplyr)
  library(tidyr)
  library(knitr)
})
# Need：mixOmics / rARPACK / RSpectra / bench
have_bench <- requireNamespace("bench", quietly = TRUE)
have_mixOmics <- requireNamespace("mixOmics", quietly = TRUE)
```

# 1. Data Preparation

```{r data-loading}
data = readRDS(file = 'Data/HaffinaCovidPBMC_30000cells_dense.rds')
data = t(data)
cat("Original data dimensions:", nrow(data), "cells x", ncol(data), "genes\n")

# Subset the data to a specified size
ncell = 1500          # choose number of cells, do not go above 2000
ngene = 2000          # choose the number of genes, do not go above 5000

set.seed(2021)
index.cell = sample(rownames(data), replace = FALSE, size = ncell)
data2 = data[index.cell, 1:ngene]

# remove genes with 0 variance
gene.var = apply(data2, 2, var)
var.zero = which(gene.var == 0)
cat("Genes with zero variance:", length(var.zero), "\n")
```

```{r data-cleaning}
# create the data ready to be analysed
data2 = data2[, setdiff(colnames(data2), names(var.zero))]
dim(data2) # data ready to be input in PCA
```

```{r data-summary}
# Check data sparsity
zero_proportion <- sum(data2 == 0) / length(data2)
cat("Zero proportion:", round(zero_proportion * 100, 2), "%\n")
cat("Data class:", class(data2), "\n")
cat("Data dimensions:", nrow(data2), "cells x", ncol(data2), "genes\n")
cat("Non-zero proportion:", round((1 - zero_proportion) * 100, 2), "%\n")

# Summary statistics
cat("\nGene expression summary:\n")
cat("  Mean expression:", round(mean(data2), 4), "\n")
cat("  Median expression:", round(median(data2), 4), "\n")
cat("  Max expression:", round(max(data2), 2), "\n")
cat("  SD:", round(sd(data2), 4), "\n")
```

# 2. Exploratory Analysis

Define methods for PCA:

```{r methods}
source("R/pca_pSVD.R")

run_pca_full <- function(X, k) {
  mixOmics::pca(X, ncomp = k, center = TRUE, scale = TRUE)
}

run_pca_psvd <- function(X, k) {
  pca_pSVD(X, ncomp = k, center = TRUE, scale = TRUE)
}
```

Both run_pca_full() and run_pca_psvd() use the same centering and scaling scheme for fair comparison.

pca_pSVD computes only the first k singular vectors using svds, theoretically equivalent to full SVD results (up to arbitrary sign flips).

## 2.1 Scree Plot Analysis

```{r scree-plot, fig.width=10, fig.height=4}
# Run PCA with max components to explore variance
k_max = min(50, min(nrow(data2), ncol(data2)) - 1)
pca_explore = run_pca_full(data2, k = k_max)

var_explained = pca_explore$prop_expl_var$X
cumvar = cumsum(var_explained)

# Create scree plots
par(mfrow = c(1, 2))

# Individual variance explained
plot(var_explained, type = "b", pch = 19, col = "steelblue",
     xlab = "Principal Component",
     ylab = "Proportion of Variance Explained",
     main = "Scree Plot",
     cex = 0.8)
abline(h = 0.01, col = "red", lty = 2, lwd = 1.5)
text(k_max * 0.7, 0.012, "1% threshold", col = "red", cex = 0.8)

# Cumulative variance explained
plot(cumvar, type = "b", pch = 19, col = "darkgreen",
     xlab = "Principal Component",
     ylab = "Cumulative Variance Explained",
     main = "Cumulative Variance Plot",
     cex = 0.8, ylim = c(0, 1))
abline(h = c(0.5, 0.8, 0.9), col = c("orange", "red", "purple"),
       lty = 2, lwd = 1.5)
legend("bottomright",
       legend = c("50%", "80%", "90%"),
       col = c("orange", "red", "purple"),
       lty = 2, bty = "n", cex = 0.8)

par(mfrow = c(1, 1))
```

The scree plot flattens quickly, with individual PCs contributing \<1% variance beyond PC 10 — a hallmark of high-dimensional, sparse data.

This visualization helps identify an effective k range (≈ 10–30 PCs) for benchmarking.

## 2.2 Variance Summary Table

```{r variance-table}
# Key variance statistics
selected_pcs = c(2, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50)
var_summary = data.frame(
  nPC = selected_pcs,
  CumulativeVar = round(cumvar[selected_pcs] * 100, 2),
  PC1_contribution = round(var_explained[1] * 100, 2),
  PC2_contribution = round(var_explained[2] * 100, 2)
)
var_summary$CumulativeVar = paste0(var_summary$CumulativeVar, "%")
var_summary$PC1_contribution[2:length(selected_pcs)] = ""
var_summary$PC2_contribution[2:length(selected_pcs)] = ""
var_summary$PC1_contribution[1] = paste0(var_summary$PC1_contribution[1], "%")
var_summary$PC2_contribution[1] = paste0(var_summary$PC2_contribution[1], "%")

kable(var_summary,
      caption = "Cumulative variance explained by different numbers of PCs",
      col.names = c("# PCs", "Cumulative Var.", "PC1 Contribution", "PC2 Contribution"))
```

The table shows how cumulative variance grows with k (≈ 13.7% at 10 PCs, 17.8% at 20 PCs). These figures serve to contextualize computational comparisons, not to interpret biological variability.

# 3. Determine Optimal k

```{r optimal-k}
# Find number of PCs to explain different variance thresholds
k_10 = which(cumvar >= 0.10)[1]
k_15 = which(cumvar >= 0.15)[1]
k_20 = which(cumvar >= 0.20)[1]
k_25 = which(cumvar >= 0.25)[1]

cat("Number of PCs needed to explain:\n")
cat("  10% variance:", k_10, "PCs\n")
cat("  15% variance:", k_15, "PCs\n")
cat("  20% variance:", k_20, "PCs\n")
cat("  25% variance:", k_25, "PCs\n")
cat("\nMaximum variance explained by", k_max, "PCs:",
    round(cumvar[k_max] * 100, 2), "%\n")
cat("      which explains the low cumulative variance in the first 50 PCs.\n")
cat("\nRecommendation: Use k = 20-30 for comprehensive exploration\n")
cat("              Or k =", k_15, "for efficient analysis (15% variance)\n")
```

Threshold-based selection (e.g., 10%, 15%, 20%, 25%) provides a reference for benchmarking at comparable representational capacities.

k = 20–30 balances efficiency and interpretability, making it suitable for comparative runtime/accuracy evaluation.

# 4. Performance Benchmark

```{r benchmark-run}
ks <- c(2, 5, 10, 20)

bench_one <- function(k) {
  if (have_bench) {
    b <- bench::mark(
      pca_full   = { run_pca_full(data2, k) },
      pca_pSVD   = { run_pca_psvd(data2, k) },
      iterations = 3, check = FALSE
    )
    tibble::tibble(
      ncomp = k,
      method = as.character(b$expression),
      time_s = as.numeric(b$median),
      mem    = as.numeric(b$mem_alloc)
    )
  } else {
    t1 <- system.time(run_pca_full(data2, k))["elapsed"]
    t2 <- system.time(run_pca_psvd(data2, k))["elapsed"]
    tibble::tibble(
      ncomp  = k,
      method = c("pca_full","pca_pSVD"),
      time_s = c(t1, t2),
      mem    = NA_real_
    )
  }
}

bench_res <- dplyr::bind_rows(lapply(ks, bench_one))
print(bench_res)
```

```{r speedup-table}
speed_tbl <- bench_res %>%
  select(ncomp, method, time_s) %>%
  pivot_wider(names_from = method, values_from = time_s) %>%
  mutate(speedup_pSVD = `pca_full` / `pca_pSVD`) %>%
  arrange(ncomp)

kable(speed_tbl, digits = 3,
      caption = "Runtime & speedup of pca_pSVD vs full SVD",
      col.names = c("k", "Full PCA (s)", "pSVD (s)", "Speedup"))
```

The speedup decreases from \~46× (k = 2) to \~17× (k = 20), reflecting that partial PCA’s efficiency is most pronounced for **low-rank approximations**.

# 5. Accuracy Validation

```{r accuracy-check}
cmp_one <- function(k) {
  f <- run_pca_full(data2, k)
  p <- run_pca_psvd(data2, k)
  tibble::tibble(
    ncomp = rep(k, k),
    method = rep("pca_pSVD", k),
    pc = seq_len(k),
    abs_diff = abs(f$prop_expl_var$X[1:k] - p$prop_expl_var$X[1:k])
  )
}

acc_res <- dplyr::bind_rows(lapply(ks, cmp_one))
acc_summary = acc_res %>%
  group_by(ncomp, method) %>%
  summarise(
    max_abs_diff = max(abs_diff),
    mean_abs_diff = mean(abs_diff),
    .groups = "drop"
  )

kable(acc_summary, digits = 10,
      caption = "Accuracy: Maximum and mean absolute differences in explained variance",
      col.names = c("k", "Method", "Max |Δ|", "Mean |Δ|"))
```

```{r loading-consistency}
# Check loading consistency between pca_full and pca_pSVD

cmp_loadings <- function(k) {
  f <- run_pca_full(data2, k)
  p <- run_pca_psvd(data2, k)

  # Compute correlation for each PC (absolute value accounts for sign flips)
  loading_corr <- sapply(1:k, function(i) {
    cor(f$loadings$X[, i], p$loadings$X[, i])
  })

  tibble::tibble(
    ncomp = k,
    pc = 1:k,
    correlation = loading_corr,
    abs_correlation = abs(loading_corr)
  )
}

loading_res <- dplyr::bind_rows(lapply(ks, cmp_loadings))

# Summary statistics
loading_summary <- loading_res %>%
  group_by(ncomp) %>%
  summarise(
    min_abs_corr = min(abs_correlation),
    mean_abs_corr = mean(abs_correlation),
    max_abs_corr = max(abs_correlation),
    all_near_1 = all(abs_correlation > 0.9999),
    .groups = "drop"
  )

kable(loading_summary, digits = 10,
      caption = "Loading consistency: Correlation between pca_full and pca_pSVD loadings",
      col.names = c("k", "Min |r|", "Mean |r|", "Max |r|", "All ≥ 0.9999"))
```

```{r accuracy-plot, fig.width=10, fig.height=6}
ggplot(acc_res, aes(pc, abs_diff, color = method)) +
  geom_line(linewidth = 0.8) +
  geom_point(size = 2) +
  facet_wrap(~ ncomp, scales = "free_x", ncol = 2) +
  scale_y_continuous(labels = scales::scientific) +
  scale_color_manual(values = c("pca_pSVD" = "steelblue")) +
  labs(x = "PC index",
       y = "Absolute difference in explained variance",
       color = "Method",
       title = "Accuracy: Explained Variance Differences vs Full PCA") +
  theme_minimal(base_size = 12) +
  theme(legend.position = "top")
```

Absolute differences in explained variance between methods are near zero (≈ 1e⁻¹⁷), confirming that both yield **identical principal components** within numerical precision limits.

# 6. Biological Interpretation

## Visual Comparison: mixOmics::pca vs pca_pSVD

```{r bio-comparison, fig.width=12, fig.height=10}
if (have_mixOmics) {
  cat("Comparing visualization between mixOmics::pca and pca_pSVD...\n\n")

  # Run both methods with k=20
  k_bio = 20
  pca_full = run_pca_full(data2, k = k_bio)
  pca_psvd = run_pca_psvd(data2, k = k_bio)

  # Set up 2x2 layout for comparison
  par(mfrow = c(2, 2))

  # mixOmics::pca - PC1 vs PC2
  mixOmics::plotIndiv(pca_full,
                      comp = c(1, 2),
                      ind.names = FALSE,
                      title = "mixOmics::pca - PC1 vs PC2",
                      pch = 16,
                      cex = 1.2,
                      col = "steelblue")

  # pca_pSVD - PC1 vs PC2
  mixOmics::plotIndiv(pca_psvd,
                      comp = c(1, 2),
                      ind.names = FALSE,
                      title = "pca_pSVD - PC1 vs PC2",
                      pch = 16,
                      cex = 1.2,
                      col = "coral")

  # mixOmics::pca - PC2 vs PC3
  mixOmics::plotIndiv(pca_full,
                      comp = c(2, 3),
                      ind.names = FALSE,
                      title = "mixOmics::pca - PC2 vs PC3",
                      pch = 16,
                      cex = 1.2,
                      col = "steelblue")

  # pca_pSVD - PC2 vs PC3
  mixOmics::plotIndiv(pca_psvd,
                      comp = c(2, 3),
                      ind.names = FALSE,
                      title = "pca_pSVD - PC2 vs PC3",
                      pch = 16,
                      cex = 1.2,
                      col = "coral")

  par(mfrow = c(1, 1))
} else {
  cat("mixOmics package not available. Skipping visualization comparison.\n")
}
```

The PC1–PC2 and PC2–PC3 scatterplots from both methods overlap nearly perfectly.

Minor mirroring or rotation is caused by arbitrary sign differences and carries **no analytical significance**.

# 7. Data Quality Metrics

```{r qc-metrics}
# Calculate data quality metrics based on exploratory analysis
qc_metrics = data.frame(
  Metric = c(
    "Total cells analyzed",
    "Total genes analyzed",
    "Data sparsity (%)",
    "Mean gene expression",
    "Variance explained by PC1 (%)",
    "Variance explained by PC1-5 (%)",
    "Variance explained by PC1-10 (%)",
    "Variance explained by PC1-20 (%)",
    "Variance explained by PC1-50 (%)",
    "Estimated optimal k (15% var.)"
  ),
  Value = c(
    nrow(data2),
    ncol(data2),
    round(zero_proportion * 100, 2),
    round(mean(data2), 4),
    round(var_explained[1] * 100, 2),
    round(sum(var_explained[1:5]) * 100, 2),
    round(sum(var_explained[1:10]) * 100, 2),
    round(sum(var_explained[1:20]) * 100, 2),
    round(cumvar[k_max] * 100, 2),
    k_15
  )
)

kable(qc_metrics, caption = "Data Quality Control Summary",
      col.names = c("Quality Metric", "Value"))
```

This summary table contextualizes the benchmarking with basic data properties—cell/gene counts, sparsity, and explained variance.

Low cumulative variance is expected in single-cell data and does not imply low PCA quality.

# 8. Discussion

This report compares **full PCA** (via mixOmics::pca) and **partial PCA** (pca_pSVD, implemented using partial SVD) in terms of **runtime**, **memory efficiency**, and **numerical accuracy** using a subset (ncell=1500, ngene=2000) of the *HaffinaCovidPBMC* single-cell dataset.

## Speed and Memory Efficiency

-   Under identical settings, partial PCA achieved **substantial speedups** compared to full PCA. For example, with k = 2/5/10/20, partial PCA was **\~46×, 37×, 25×, and 17× faster**, respectively.

-   Memory usage was also reduced by nearly half (\~245 MB vs \~480 MB).

-   As expected, the **relative speedup decreases** as k increases, since truncated SVD loses efficiency when k approaches min(n, p).

## Numerical Accuracy

-   The **explained variance** difference between full PCA and partial PCA was at the **machine precision level (\~1e⁻¹⁷)**, confirming that partial PCA produces equivalent principal components.

-   **Loadings correlation** between the two methods was nearly **1.0 (\|r\| ≥ 0.9999)** across all PCs, which is consistent with theoretical expectations (differences are limited to random sign flips).

-   **Scatter plots (PC1–PC2, PC2–PC3)** produced visually indistinguishable results between both methods; small reflections or rotations correspond only to sign indeterminacy.

## Practical Recommendations

-   When k ≪ min(n, p) or the matrix is sparse, **partial PCA is highly recommended**—it maintains identical results while significantly reducing compute time.

-   For very large k or convergence issues in svds, fallback to **full PCA** is appropriate.

-   In this experiment, cumulative variance explained by the first 50 PCs was **\~26.6%**, with **\~18–21% by 20–30 PCs**—typical for high-dimensional, sparse single-cell data. These values are contextual, not biological conclusions.

## Compatibility Test

To ensure [`pca_pSVD`](https://github.com/dereklei12/pca_R/blob/main/R/pca_pSVD.R) produces reliable and consistent results across different platforms and environments, a test suite was developed using the `testthat` framework. The complete test file is available at: [test-pca_pSVD.R](https://github.com/dereklei12/pca_R/blob/main/test/testthat/test-pca_pSVD.R).

The test suite validates the following scenarios:

1.  **Basic Functionality**: Verifies correct output structure, dimensions, and class inheritance (`pca_pSVD` and `pca`).

2.  **Consistency with Base R and mixOmics**: Compares results (singular values, variance explained, loadings) against `prcomp` and `mixOmics::pca`, accounting for sign ambiguity in PCA.

3.  **Input Validation**: Tests handling of invalid inputs (non-numeric data, incorrect dimensions, invalid parameter values).

4.  **Sparse Matrix Support**: Validates compatibility with sparse matrix formats (`dgCMatrix`, `dgRMatrix`) from the `Matrix` package.

5.  **Edge Cases**: Tests behavior with small, wide (n \< p), and tall (n \> p) matrices, as well as zero-variance columns.

6.  **Centering and Scaling Options**: Verifies all combinations of `center` and `scale` parameters, including numeric vectors.

7.  **Multilevel Analysis**: Confirms proper handling of repeated-measures designs and consistency with `mixOmics::pca` multilevel results.

8.  **Fallback Mechanisms**: Tests graceful degradation when specialized SVD packages (`RSpectra`, `rARPACK`) are unavailable, and appropriate delegation to `mixOmics` for missing values or ILR transformations.

9.  **Cross-Platform Numerical Stability**: Ensures orthonormality of loadings, monotonicity of eigenvalues, and validity of variance proportions across different computing environments.

All tests passed successfully, confirming that `pca_pSVD` is robust, reliable, and compatible with existing R PCA implementations. Continuous integration testing across multiple platforms (Ubuntu, Windows, macOS) is automated; detailed results are available via [GitHub Actions](https://github.com/dereklei12/pca_R/actions).

## Limitations and Reproducibility

-   Speedup depends on hardware, BLAS implementation, and data sparsity.

-   For this dataset, multilevel analysis was not performed (multilevel = NULL) and logratio transformation was set to "none". These parameter choices prioritize computational efficiency comparison rather than biological interpretation.

-   Both methods were executed with identical preprocessing (center = TRUE, scale = TRUE) and a fixed random seed for reproducibility.

# 9. Session Info

```{r session-info}
sessionInfo()
```
